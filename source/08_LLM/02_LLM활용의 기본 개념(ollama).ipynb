{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290d4a8",
   "metadata": {},
   "source": [
    "<font color='red'>LLM활용의 기본개념</font>\n",
    "\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "\n",
    "## 1) Ollama 이용한 로컬 LLM이용\n",
    "성능은 GPT, Claude 같은 모델보다 떨어지나, 개념 설명을 위해 open source 모델 사용\n",
    "\n",
    "### ⓐ ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama run deepseek-r1:1.5b (window키+R : powershell창)\n",
    "- llama : 공식적으로 한글지원 안 됨(lllama 3.1 405b, 3.3 70b 한글기능 좋음)\n",
    "- exaone : 공식적으로 한글지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb312392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "한국의 hematogensic capacity, or simply its blood circulation system, refers to the efficiency and effectiveness of blood flow within the body. This includes the heart rate, blood pressure, vessel structure, and the presence of adequate blood vessels for delivering oxygen and nutrients to all parts of the body.\n",
      "\n",
      "Here are some key factors that affect your country's blood circulation capacity:\n",
      "\n",
      "1. **Heart Function**: The strength and speed of your heart muscle significantly impact your blood flow efficiency.\n",
      "2. **Vessel Condition**: The health of the blood vessels, including their diameter, elasticity, and smoothness, affects how well blood can circulate.\n",
      "3. **Blood Pressure and Venous Return**: Proper regulation of blood pressure in the arteries (venous return) ensures that oxygen and nutrients are delivered to all tissues and waste is removed properly.\n",
      "4. **Vascular Smooth Muscle**: The type of vascular smooth muscle cells (e.g., smooth muscle, elastic, or fibrous) affects the flexibility and conductivity of the blood vessels.\n",
      "\n",
      "A highly functional blood circulation system in your country can improve overall health by enabling efficient oxygenation and removal of waste products from all tissues.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke('한국의 수도는?')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8815de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 수도는 Seoul입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "result = llm.invoke('한국의 수도는?')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c723b7",
   "metadata": {},
   "source": [
    "## 2) openai 활용\n",
    "- pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a06fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 수도는 서울입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "result = llm.invoke('한국의 수도는?')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6871c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model='gpt-4o-nano')\n",
    "# result = llm.invoke('한국의 수도는?')\n",
    "\n",
    "# OPENAI_API_VERSION 환경변수가 필요하다는 메세지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707927aa",
   "metadata": {},
   "source": [
    "# 2. 랭체인 스타일로 프롬프트 작성하기\n",
    "- 프롬프트 : llm 호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa5eb203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"iron\" can have different meanings depending on the context. Here are a few possible interpretations:\n",
      "\n",
      "1. **Chemical element**: Iron is a chemical element with the symbol Fe and atomic number 26. It's a transition metal that's essential for many biological processes, including oxygen transport in the blood.\n",
      "2. **Physical property**: In physics, iron can refer to the physical properties of the element, such as its density (7.9 g/cm³), melting point (1534°C), and boiling point (2866°C).\n",
      "3. **Symbolism and culture**: Iron is also a symbol with rich cultural significance. For example, in ancient Greek mythology, Prometheus was a titan who defied Zeus by stealing fire from the gods and giving it to humanity. This story has become synonymous with strength, courage, and defiance.\n",
      "4. **Agriculture and industry**: In agriculture, iron is often used as a fertilizer or soil conditioner, helping plants grow stronger and healthier. In industries like construction and manufacturing, iron is widely used for making tools, machinery, and other equipment.\n",
      "\n",
      "In everyday language, the term \"iron\" can also refer to:\n",
      "\n",
      "* **Iron lung**: an oxygenator that uses air pressure to breathe for people with respiratory failure.\n",
      "* **Iron curtain**: a metaphor for the Iron Curtain, a physical barrier or division between Eastern and Western Europe during the Cold War.\n",
      "* **Iron maiden**: a nickname for Queen Elizabeth II, who was known for her strict adherence to tradition and protocol.\n",
      "\n",
      "I hope this helps clarify the different meanings of \"iron\"!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "result = llm.invoke('what is the iron')\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de0fc6",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e36a5b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T05:30:55.5153831Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2899073400, 'load_duration': 1710976000, 'prompt_eval_count': 32, 'prompt_eval_duration': 637924500, 'eval_count': 9, 'eval_duration': 544369100, 'model_name': 'llama3.2:1b'}, id='run--7b9a6c1d-e197-472a-93aa-f6f18b3f1019-0', usage_metadata={'input_tokens': 32, 'output_tokens': 9, 'total_tokens': 41})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the {thing} of {country}\", # {}안의 값을 새로운 값으로 할당 가능\n",
    "    input_variables=['country','thing']\n",
    ")\n",
    "llm.invoke(prompt_template.invoke({'country':'korea','thing':'capital'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ec5a6",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속 받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df4fc89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You ara a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Korea?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Seoul.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of {country}?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list =[\n",
    "    SystemMessage(content=\"You ara a helpful assistant!\"),\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),\n",
    "    HumanMessage(content=\"What is the capital of Korea?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of {country}?\")\n",
    "]\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages(message_list)\n",
    "prompt = chatPromptTemplate.invoke({'country':'Korea'})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea06a57",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMesaage 리스트 -> 튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b29d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 messages=[SystemMessage(content='너는 훌륭한 도우미다', additional_kwargs={}, response_metadata={}), HumanMessage(content='한국의 수도는 서울입니다', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'공화국에서 가장 큰 주도城市이기도 하는 서울은 indeed 한국의 수도です! 주류 도시가 되었습니다.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    ('system','너는 훌륭한 도우미다'),\n",
    "    ('human', '{country}의 수도는 서울입니다')\n",
    "])\n",
    "country = input('나라이름 입력;')\n",
    "prompt = chatPromptTemplate.invoke({'country':country})\n",
    "print('프롬프트',prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786fd1d",
   "metadata": {},
   "source": [
    "# 3. 답변 형식을 컨트롤하기\n",
    "- invoke 실행결과는 AIMessage() -> String이나 json, 객체 : outputParser이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18a0902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 : text='What is the capital of Korea. Return the name of the city only'\n",
      "llm결과 : <class 'langchain_core.messages.ai.AIMessage'>\n",
      "파서 결과 : Seoul\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template= 'What is the capital of {country}. Return the name of the city only',\n",
    "    input_variables= ['country']\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({'country':'Korea'})\n",
    "print('프롬프트 :',prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print('llm결과 :',type(result))\n",
    "# 문자열 출력 파서를 이용하여 LLM 응답을 단순 문자열 변환\n",
    "output_parser = StrOutputParser()\n",
    "print('파서 결과 :', output_parser.invoke(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa6e4914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate(변수설정) => ChatPromptTemplate(변수설정, system과 모법답안 지정)\n",
    "llm = ChatOllama(model='llama3.2:1b')\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful assistant with expertise in South Korea'),\n",
    "    ('human', 'What is the capital of {country}? Return the name if the city only.')\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({'country':'Korea'})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9280ab",
   "metadata": {},
   "source": [
    "## 2) 응답 타입 확인\n",
    "- json()으로 응답하기를 원하지만, 우선 어떤 형식으로 반환되는지 확인\n",
    "- {'name':'홍','age':22}(json) /{'name':'홍','age':22}(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b34471c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "```\n",
      "{\n",
      "    \"capital\": \"Seoul\",\n",
      "    \"population\": 51.8,\n",
      "    \"language\": \"Korean\",\n",
      "    \"currency\": \"South Korean won\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables= ['country']\n",
    "    )\n",
    "prompt = country_detail_prompt.invoke({'country':'Korea'})\n",
    "print(type(prompt))\n",
    "# Json output 파서\n",
    "output_parser = JsonOutputParser()\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "392eb592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Seoul',\n",
       " 'population': '51,381,476',\n",
       " 'language': 'Korean',\n",
       " 'currency': 'KRW'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables= ['country']\n",
    "    )\n",
    "output_parser = JsonOutputParser()\n",
    "info = output_parser.invoke(llm.invoke(country_detail_prompt.invoke({'country':'Korea'})))\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231aa0a",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic : 모델을 사용하여 LLM 출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c3b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x000001B669DDE4D0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class User:\n",
    "    def __init__(self, id, name, is_activate=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_activate = is_activate\n",
    "user = User(1,'홍길동')\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5b29bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_activate=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    id:int  = Field(gt=0, description='id') # gt: id>0, ge: id>=0, lt: id<0, le: id<=0\n",
    "    name:str = Field(min_length=2, description='name')\n",
    "    is_activate:bool = Field(default=True, description='True')\n",
    "user = User(id=1, name='홍길동')\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c93e0954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables= ['country']\n",
    "    )\n",
    "class CountryDetail(BaseModel): # description : 더 정확한 출력 유도\n",
    "    capital:str     = Field(description='the capital of the country')\n",
    "    population:int  = Field(description='the population of the country')\n",
    "    language:str    = Field(description='the language of the country')\n",
    "    currency:str    = Field(description='the currency of the country')\n",
    "\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "\n",
    "# 기존 출력방식\n",
    "# output_parser = JsonOutputParser()\n",
    "# output_parser.invoke(llm.invoke(country_detail_prompt.invoke({'country':'Korea'})))\n",
    "\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({'country':'Korea'}))\n",
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde8622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital='Seoul' population=51 language='Korean (official)' currency='South Korean won'\n",
      "Seoul 51\n"
     ]
    }
   ],
   "source": [
    "print(info)\n",
    "print(info.capital, info.population) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "70b02712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean (official)\",\"currency\":\"South Korean won\"}\n",
      "info를 dict : {'capital': 'Seoul', 'population': 51, 'language': 'Korean (official)', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print('info를 json :', info.model_dump_json()) # type: ignore\n",
    "print('info를 dict :', info.model_dump()) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6cb11",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 랭체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6073e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model='llama3.2:1b', temperature=0) # 일관된 답변\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template= 'What is the capital of {country}. Return the name of the city only',\n",
    "    input_variables= ['country']\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({'country':'Korea'})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235277f",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자(|) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "daea6307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "captial_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "captial_chain.invoke({'country':'Korea'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aba457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110e477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
