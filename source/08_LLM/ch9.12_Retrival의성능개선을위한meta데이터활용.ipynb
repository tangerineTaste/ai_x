{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85aa76a",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(46, 204, 113);\">1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜</span>\n",
    "- ê°€ìƒí™˜ê²½ ë§Œë“  ë’¤, pip install ipykernel ì‹¤í–‰\n",
    "- ì•„ë˜ì˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01428be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv langchain langchain-openai langchain-pinecone pinecone pandas langchain-community docx2txt langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9b763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain_ollama "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fa851",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(46, 204, 113);\">2. í™˜ê²½ ì„¤ì •(í™˜ê²½ë³€ìˆ˜, ì‹œìŠ¤í…œíŒŒë¼ë¯¸í„°ë³€ìˆ˜)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93f6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"e:/.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_LLM_MODEL = \"gpt-4o-mini\"\n",
    "OPENAI_EMBEDDING_MODEL=\"text-embedding-3-large\" # small ë²„ì „ì€ 1536ì°¨ì›, upstageëŠ” 4096\n",
    "\n",
    "PINECONE_INDEX_NAME=\"better-reg-index\"\n",
    "PINECONE_INDEX_DIMENSION = 3072\n",
    "PINECONE_INDEX_METRIC=\"cosine\"\n",
    "PINECONE_INDEX_REGION=\"us-east-1\"\n",
    "PINECONE_INDEX_CLOUD=\"aws\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bc089",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(46, 204, 113);\">3. ë¬¸ì„œë¥¼ chunkë¡œ ë¶„í• í•˜ê¸°</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8c1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 64ê°œ ì²­í¬ ìƒì„±\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# loader = Docx2txtLoader('./data/with_markdown-sample.docx')\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "# documents = loader.load_and_split(text_splitter) ## ì´ë ‡ê²Œ \"\\n\"ë‹¨ìœ„ë¡œ chunkë¥¼ ì•ˆ ë‚˜ëˆ„ê³ \n",
    "\n",
    "loader = Docx2txtLoader('./tax_docs/with_markdown-sample.docx')\n",
    "document = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1500,\n",
    "  chunk_overlap=200,\n",
    "  separators=[\"\\n\\n\", \"\\n\", \"ì œ\", \"ì¡°\", \".\", \" \"]\n",
    ")\n",
    "documents = text_splitter.split_documents(document)\n",
    "print(f\"ì´ {len(documents)}ê°œ ì²­í¬ ìƒì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681db3b",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(46, 204, 113);\">4. metadata ì¶”ê°€í•˜ê¸°</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43865bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì†Œë“ì„¸ ë‚©ì„¸ ì˜ë¬´: ê±°ì£¼ì ë° êµ­ë‚´ì›ì²œì†Œë“ì, ì›ì²œì§•ìˆ˜ ëŒ€ìƒ ê°œì¸ ë° ë²•ì¸ í¬í•¨.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_chars(text: str) -> str:\n",
    "    \"\"\"íŠ¹ìˆ˜ë¬¸ì ë° \\nì œê±°(:ëŠ” ê·¸ëŒ€ë¡œ)\"\"\"\n",
    "    # \\n ì œê±°\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ë§ˆì¹¨í‘œ, ì½¤ë§ˆë§Œ ë‚¨ê¸°ê³  ì „ë¶€ ì œê±°\n",
    "    cleaned = re.sub(r'[^ê°€-í£a-zA-Z0-9\\s.,:]', '', text)\n",
    "    # ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ê³µë°± ì œê±°\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "content = \"**ì†Œë“ì„¸ ë‚©ì„¸ ì˜ë¬´**: ê±°ì£¼ì ë° êµ­ë‚´ì›ì²œì†Œë“ì, ì›ì²œì§•ìˆ˜ ëŒ€ìƒ ê°œì¸ ë° ë²•ì¸ í¬í•¨.\"\n",
    "print(remove_special_chars(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f63e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10404\\3252744802.py:4: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  title_extractor_llm = ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì†Œë“ì„¸ ê³¼ì„¸ê¸°ê°„ : ì—° 1ì›”12ì›”, ì‚¬ë§ ì‹œ ì‚¬ë§ì¼ê¹Œì§€, êµ­ì™¸ ì´ì „ ì‹œ ì¶œêµ­ì¼ê¹Œì§€\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "def extract_title_with_llm(content):\n",
    "  \"\"\"Exaoneì„ ì‚¬ìš©í•´ì„œ ì œëª© ì¶”ì¶œ\"\"\"\n",
    "  title_extractor_llm = ChatOllama(\n",
    "                model=\"exaone3.5:2.4b\",\n",
    "                temperature=0.1, # 0ì— ê°€ê¹Œìš°ë©´ ë‹µë³€ì´ ì¼ê´€ì \n",
    "                num_predict=30 # ìµœëŒ€ í† ê·¼ 30í† í°ê¹Œì§€ë§Œ ì¶œë ¥\n",
    "            )\n",
    "  prompt = f'''ë‹¤ìŒ ì†Œë“ì„¸ë²• ì¡°ë¬¸ì˜ í•µì‹¬ ì œëª©ì„ 30í† í° ì´ë‚´ë¡œ ê°„ë‹¨íˆ ì™„ë²½í•˜ê²Œ ë§ì´ ë˜ë„ë¡ ì¶”ì¶œí•´ ì£¼ì„¸ìš”. ì¤‘ê°„ì— ë§ì´ ëŠê¸°ë©´ ì•ˆ ë˜ìš”.\n",
    "  ì˜ˆ : \"ì†Œë“ì„¸ ë‚©ì„¸ì˜ë¬´ ë²”ìœ„ : ê³µë™ì‚¬ì—…ìë³„ ì†Œë“ê³¼ì„¸, ìƒì†ê³¼ì„¸, ì¦ì—¬ì\"\n",
    "  ì¡°ë¬¸ : {content}'''\n",
    "  ai_message = title_extractor_llm.invoke(prompt)\n",
    "  title = ai_message.content.strip()\n",
    "  return remove_special_chars(title)\n",
    "content = \"\"\"ì œ5ì¡°(ê³¼ì„¸ê¸°ê°„) â‘  ì†Œë“ì„¸ì˜ ê³¼ì„¸ê¸°ê°„ì€ 1ì›” 1ì¼ë¶€í„° 12ì›” 31ì¼ê¹Œì§€ 1ë…„ìœ¼ë¡œ í•œë‹¤.\n",
    "â‘¡ ê±°ì£¼ìê°€ ì‚¬ë§í•œ ê²½ìš°ì˜ ê³¼ì„¸ê¸°ê°„ì€ 1ì›” 1ì¼ë¶€í„° ì‚¬ë§í•œ ë‚ ê¹Œì§€ë¡œ í•œë‹¤.\n",
    "â‘¢ ê±°ì£¼ìê°€ ì£¼ì†Œ ë˜ëŠ” ê±°ì†Œë¥¼ êµ­ì™¸ë¡œ ì´ì „(ì´í•˜ â€œì¶œêµ­â€ì´ë¼ í•œë‹¤)í•˜ì—¬ ë¹„ê±°ì£¼ìê°€ ë˜ëŠ” ê²½ìš°ì˜ ê³¼ì„¸ê¸°ê°„ì€ 1ì›” 1ì¼ë¶€í„° ì¶œêµ­í•œ ë‚ ê¹Œì§€ë¡œ í•œë‹¤.\n",
    "\"\"\"\n",
    "print(extract_title_with_llm(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87481563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‚©ì„¸ì˜ë¬´'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_content(content):\n",
    "    \"\"\"ë‚´ìš© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜\"\"\"\n",
    "    # ì³‡ gptê°€ meta ë°ì´í„°ì— ì“´ë‹¤ê³  í•˜ë‹ˆ ë§Œë“¤ì–´ ì¤€ ì¹´í…Œê³ ë¦¬\n",
    "    categories = {\n",
    "    'ë‚©ì„¸ì˜ë¬´': ['ë‚©ì„¸ì˜ë¬´', 'ê±°ì£¼ì', 'ë¹„ê±°ì£¼ì', 'ì›ì²œì§•ìˆ˜', 'ê³µë™ì‚¬ì—…ì', 'ìƒì†ì¸', 'ì¦ì—¬ì', 'ì‹ íƒì¬ì‚°'],\n",
    "    'ì„¸ìœ¨ê³„ì‚°': ['ì„¸ìœ¨', 'ê³¼ì„¸í‘œì¤€', 'ì‚°ì¶œì„¸ì•¡', 'ê²°ì •ì„¸ì•¡', 'ì¢…í•©ì†Œë“', 'í‡´ì§ì†Œë“'],\n",
    "    'ê·¼ë¡œì†Œë“': ['ê·¼ë¡œì†Œë“', 'ì´ê¸‰ì—¬', 'ê¸‰ì—¬', 'ì—°ë´‰', 'ì„ê¸ˆ', 'í‡´ì§ì†Œë“'],\n",
    "    'ì‚¬ì—…ì†Œë“': ['ì‚¬ì—…ì†Œë“', 'ê³µë™ì‚¬ì—…', 'ì£¼íƒì„ëŒ€ì†Œë“', 'ë¶€ì—…ì†Œë“'],\n",
    "    'ì´ìë°°ë‹¹': ['ì´ìì†Œë“', 'ë°°ë‹¹ì†Œë“', 'ì˜ˆê¸ˆì´ì', 'ì±„ê¶Œ', 'ì˜ì œë°°ë‹¹'],\n",
    "    'ì–‘ë„ì†Œë“': ['ì–‘ë„ì†Œë“', 'ìì‚°ì–‘ë„', 'ë¶€ë™ì‚°ì–‘ë„', 'ì£¼ì‹ì–‘ë„'],\n",
    "    'ì—°ê¸ˆì†Œë“': ['ì—°ê¸ˆì†Œë“', 'ê³µì ì—°ê¸ˆ', 'ì‚¬ì ì—°ê¸ˆ', 'ì—°ê¸ˆë³´í—˜'],\n",
    "    'ê¸°íƒ€ì†Œë“': ['ê¸°íƒ€ì†Œë“', 'ìƒê¸ˆ', 'ë³´ìƒê¸ˆ', 'ë°œëª…ë³´ìƒê¸ˆ', 'ì¢…êµì¸ì†Œë“'],\n",
    "    'ê³µì œê°ë©´': ['ê³µì œ', 'ì†Œë“ê³µì œ', 'ì„¸ì•¡ê³µì œ', 'ê¸°ë³¸ê³µì œ', 'ê°ë©´'],\n",
    "    'ë¹„ê³¼ì„¸': ['ë¹„ê³¼ì„¸', 'ë©´ì œ', 'ë³µë¬´ê¸‰ì—¬', 'ì‹¤ì—…ê¸‰ì—¬', 'ì¶œì‚°íœ´ê°€ê¸‰ì—¬', 'ì¥í•™ê¸ˆ'],\n",
    "    'ì‹ ê³ ë‚©ë¶€': ['ì‹ ê³ ', 'ë‚©ë¶€', 'ë‚©ì„¸ì§€', 'ì‹ ê³ ê¸°í•œ', 'ì›ì²œì§•ìˆ˜'],\n",
    "    'ê³¼ì„¸ê¸°ê°„': ['ê³¼ì„¸ê¸°ê°„', 'ê³¼ì„¸ì—°ë„', 'ì‚¬ì—…ì—°ë„'],\n",
    "    'ê³¼ì„¸ì†Œë“êµ¬ë¶„': ['ì¢…í•©ì†Œë“', 'í‡´ì§ì†Œë“', 'ì–‘ë„ì†Œë“', 'ê¸ˆìœµíˆ¬ìì†Œë“'],\n",
    "    }\n",
    "    # categories = []\n",
    "    for category, keywords in categories.items():\n",
    "        if any(keyword in content for keyword in keywords):\n",
    "            # categories.append(category)\n",
    "            return category\n",
    "    if categories:\n",
    "        categories.append('ê¸°íƒ€')\n",
    "    #return categories\n",
    "    return 'ê¸°íƒ€'\n",
    "categorize_content(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exaoneìœ¼ë¡œ ì œëª© ì¶”ì¶œ ì¤‘...\n",
      "   ì§„í–‰: 0/64\n",
      "   ì§„í–‰: 10/64\n",
      "   ì§„í–‰: 20/64\n",
      "   ì§„í–‰: 30/64\n"
     ]
    }
   ],
   "source": [
    "# Exaoneìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "enhanced_chunks = []\n",
    "print(\"Exaoneìœ¼ë¡œ ì œëª© ì¶”ì¶œ ì¤‘...\")\n",
    "for i, chunk in enumerate(documents):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"   ì§„í–‰: {i}/{len(documents)}\")\n",
    "    content = chunk.page_content\n",
    "    metadata = chunk.metadata.copy()\n",
    "    # Exaoneìœ¼ë¡œ ì œëª© ì¶”ì¶œ\n",
    "    metadata['title'] = extract_title_with_llm(content) # llmìœ¼ë¡œ ì œëª© ë½‘ê¸°\n",
    "    metadata['category'] = categorize_content(content) # ì¹´í…Œê³ ë¦¬ ë½‘ê¸°\n",
    "    metadata['chunk_id'] = f\"chunk_{i:03d}\"\n",
    "    # ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ\n",
    "    article_match = re.search(r'ì œ(\\d+)ì¡°', content)\n",
    "    if article_match:\n",
    "        metadata['article'] = int(article_match.group(1))\n",
    "\n",
    "    enhanced_chunks.append(type(chunk)(\n",
    "        page_content=content,\n",
    "        metadata=metadata\n",
    "    ))\n",
    "print(f\"âœ… {len(enhanced_chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "enhanced_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "34eab1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './data/with_markdown-sample.docx',\n",
       " 'title': 'ì†Œë“ì„¸ë²•: ê°œì¸ ë° ë²•ì¸ì˜ ì†Œë“ì— ë”°ë¥¸ ì ì • ê³¼ì„¸ ê·œì •',\n",
       " 'category': 'ë‚©ì„¸ì˜ë¬´',\n",
       " 'chunk_id': 'chunk_000',\n",
       " 'article': 1}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_chunks[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# enhanced_chunksë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "data = []\n",
    "for chunk in enhanced_chunks:\n",
    "    row = {\"page_content\": chunk.page_content[:10]}\n",
    "    row.update(chunk.metadata)  # metadata ë”•ì…”ë„ˆë¦¬ì˜ key/value ì¶”ê°€\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV ì €ì¥\n",
    "df.to_csv(\"./tax_docs/enhanced_chunks.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98024c",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(46, 204, 113);\">5. OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì •</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "14185bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=OPENAI_EMBEDDING_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0804f0",
   "metadata": {},
   "source": [
    "### <span style=\"color: rgb(46, 204, 113);\">6. Pinecone ì¸ë±ìŠ¤ ìƒì„± ë° vector store(DB) ì €ì¥</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11e448c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINECONE_API_KEYì˜ pinecone indexë“¤ : ['tax-index', 'reg-retrieval']\n",
      "ì¸ë±ìŠ¤ 'better-reg-index' ìƒì„± ì™„ë£Œ\n",
      "PINECONE_API_KEYì˜ pinecone indexë“¤ : ['tax-index', 'better-reg-index', 'reg-retrieval']\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Pinecone í´ë¼ì´ì–¸íŠ¸\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "print('PINECONE_API_KEYì˜ pinecone indexë“¤ :',pc.list_indexes().names())\n",
    " \n",
    "# index = pc.Index(PINECONE_INDEX_NAME)\n",
    "# index.delete(delete_all=True)\n",
    "# print(\"ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "# ì¸ë±ìŠ¤ ìƒì„± ì—¬ë¶€ í™•ì¸ ë° ìƒì„±\n",
    "# if PINECONE_INDEX_NAME not in pc.list_indexes().names():\n",
    "if not pc.has_index(PINECONE_INDEX_NAME):\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME, \n",
    "        dimension=PINECONE_INDEX_DIMENSION, \n",
    "        metric=PINECONE_INDEX_METRIC,\n",
    "        spec=ServerlessSpec(region=PINECONE_INDEX_REGION,\n",
    "                            cloud=PINECONE_INDEX_CLOUD\n",
    "        )\n",
    "    )\n",
    "    print(f\"ì¸ë±ìŠ¤ '{PINECONE_INDEX_NAME}' ìƒì„± ì™„ë£Œ\")\n",
    "else:\n",
    "    print(f\"ì¸ë±ìŠ¤ '{PINECONE_INDEX_NAME}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print('PINECONE_API_KEYì˜ pinecone indexë“¤ :',pc.list_indexes().names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e4ed10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°±í„°DB ì €ì¥\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Pinecone ë²¡í„° ìŠ¤í† ì–´ ì—°ê²°\n",
    "vector_database = PineconeVectorStore.from_documents(\n",
    "                documents=enhanced_chunks,\n",
    "                embedding=embedding,\n",
    "                index_name=PINECONE_INDEX_NAME\n",
    "            )\n",
    "print(\"ë°±í„°DB ì €ì¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "77db18f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì´ê¸‰ì—¬ì•¡ 5000ë§Œì›ì¸ ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ìì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì˜ˆìš”?'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "keyword_dict  = [\n",
    "    \"ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì\",\n",
    "    \"ì§ì¥ì¸ -> ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ì\", \n",
    "    \"ì›”ê¸‰ìŸì´ -> ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ì\",\n",
    "    \"íšŒì‚¬ì› -> ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ì\",\n",
    "    \"ì—°ë´‰ -> ì´ê¸‰ì—¬ì•¡\",\n",
    "    \"ì›”ê¸‰ -> ê·¼ë¡œì†Œë“\",\n",
    "    \"ì„¸ê¸ˆ -> ì†Œë“ì„¸\",\n",
    "    \"ê³µì œë°›ë‹¤ -> ê³µì œë¥¼ ì ìš©ë°›ë‹¤\",\n",
    "    \"ì–¼ë§ˆë‚˜ ë‚´ì•¼í•˜ë‚˜ -> ì„¸ì•¡ì€ ì–¼ë§ˆì¸ê°€\",\n",
    "    \"ê³„ì‚°í•´ì¤˜ -> ê³„ì‚°í•˜ë©´ ì–¼ë§ˆì¸ê°€\"\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ \n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ ì£¼ì„¸ìš”. ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ì„ê²½ìš°, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.\n",
    "ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ ì£¼ì„¸ìš”.\n",
    "ì‚¬ì „: {keyword_dict}\n",
    "ì§ˆë¬¸: {{question}}\n",
    "\"\"\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0,\n",
    "                api_key=OPENAI_API_KEY)\n",
    "keyword_chain = prompt | llm | StrOutputParser()\n",
    "keyword_chain.invoke({\"question\":\"ì—°ë´‰ 5000ë§Œì›ì¸ íšŒì‚¬ì›ì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì˜ˆìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e5ce64eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ê·¼ë¡œì†Œë“'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize_content(\"ì—°ë´‰ 5000ë§Œì›ì¸ íšŒì‚¬ì›ì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì˜ˆìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ ì†Œë“ì„¸ ì „ìš© í”„ë¡¬í”„íŠ¸\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ìµœê³ ì˜ í•œêµ­ ì†Œë“ì„¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤\"),\n",
    "    (\"human\", \"\"\"ë‹¤ìŒê³¼ ê°™ì€ ê²€ìƒ‰ëœ ë¬¸ë§¥ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. \n",
    "ë‹µì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”. \n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ë¬¸ë§¥: {context}\n",
    "ë‹µë³€:\"\"\")\n",
    "])\n",
    "retriever = vector_database.as_retriever(\n",
    "  search_kwargs={\n",
    "                \"k\": 4,\n",
    "                \"filter\": {\n",
    "                    \"category\": {\"$in\": [\"ì„¸ìœ¨ê³„ì‚°\", \"ê·¼ë¡œì†Œë“\", \"ê³µì œê°ë©´\"]} # 3ê°œì˜ ì¹´í…Œê³ ë¦¬ë§Œ ê²€ìƒ‰\n",
    "                    # titleì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë§Œ ê²€ìƒ‰(ë¹„ì¶”. ì œëª©ì€ rerankì— ë§ì´ ì“°ì„ 20ê°œì¯¤ ìœ ì‚¬í•œ ê²ƒì„ ë½‘ë‹¤ ì œëª©ê³¼ ìœ ì‚¬ë„ê°€ ë†’ì€ ê²ƒìœ¼ë¡œ ë‹¤ì‹œ rerankí•¨)\n",
    "                    #{\"title\": {\"$regex\": f\"({'|'.join(title_keywords)})\"}} if title_keywords else {}\n",
    "                }\n",
    "            }\n",
    ")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    retriever = retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "full_chain = {\"query\": keyword_chain} | qa_chain\n",
    "results = full_chain.invoke({\"question\":\"ì—°ë´‰ 5000ë§Œì›ì¸ íšŒì‚¬ì›ì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì˜ˆìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5c48c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ê¸‰ì—¬ì•¡ 5,000ë§Œì›ì¸ ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ìì˜ ì†Œë“ì„¸ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ì†Œë“ì„¸ìœ¨ê³¼ ì„¸ì•¡ê³µì œë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. \n",
      "\n",
      "2023ë…„ ê¸°ì¤€ìœ¼ë¡œ í•œêµ­ì˜ ê·¼ë¡œì†Œë“ì„¸ìœ¨ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. 1,200ë§Œì› ì´í•˜: 6%\n",
      "2. 1,200ë§Œì› ì´ˆê³¼ ~ 4,600ë§Œì› ì´í•˜: 15%\n",
      "3. 4,600ë§Œì› ì´ˆê³¼ ~ 8,800ë§Œì› ì´í•˜: 24%\n",
      "4. 8,800ë§Œì› ì´ˆê³¼ ~ 1ì–µ5ì²œë§Œì› ì´í•˜: 35%\n",
      "5. 1ì–µ5ì²œë§Œì› ì´ˆê³¼: 38%\n",
      "\n",
      "ì´ê¸‰ì—¬ì•¡ 5,000ë§Œì›ì— ëŒ€í•œ ì†Œë“ì„¸ë¥¼ ê³„ì‚°í•´ë³´ë©´:\n",
      "\n",
      "1. 1,200ë§Œì›ì— ëŒ€í•œ ì„¸ê¸ˆ: 1,200ë§Œì› Ã— 6% = 72ë§Œì›\n",
      "2. 1,200ë§Œì› ì´ˆê³¼ 4,600ë§Œì›ê¹Œì§€ (3,400ë§Œì›)ì— ëŒ€í•œ ì„¸ê¸ˆ: 3,400ë§Œì› Ã— 15% = 510ë§Œì›\n",
      "3. 4,600ë§Œì› ì´ˆê³¼ 5,000ë§Œì›ê¹Œì§€ (400ë§Œì›)ì— ëŒ€í•œ ì„¸ê¸ˆ: 400ë§Œì› Ã— 24% = 96ë§Œì›\n",
      "\n",
      "ì´ì œ ì´ ì„¸ì•¡ì„ ëª¨ë‘ í•©ì‚°í•©ë‹ˆë‹¤:\n",
      "\n",
      "- 72ë§Œì› + 510ë§Œì› + 96ë§Œì› = 678ë§Œì›\n",
      "\n",
      "ë”°ë¼ì„œ, ì´ê¸‰ì—¬ì•¡ 5,000ë§Œì›ì¸ ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ìì˜ ì†Œë“ì„¸ëŠ” ì•½ 678ë§Œì›ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë‹¨, ì´ ê³„ì‚°ì€ ê¸°ë³¸ì ì¸ ì„¸ìœ¨ë§Œì„ ì ìš©í•œ ê²ƒì´ë©°, ì‹¤ì œ ì„¸ì•¡ì€ ê°ì¢… ì„¸ì•¡ê³µì œë‚˜ ì¶”ê°€ì ì¸ ì†Œë“ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aec2b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ:\n",
      "   1. [ê·¼ë¡œì†Œë“] ì†Œë“ì„¸ ê°ë©´ ë° ê³µì œ ì¡°í•­: í•´ì™¸ê·¼ë¬´ ê¸‰ì—¬, êµ­ê°€ìœ ê³µì ì§€ì›ê¸ˆ, ì „ì§ëŒ€í†µë ¹ ì—°ê¸ˆ, êµ°ì¸êµ°ë¬´ì› ê¸‰ì—¬, ì „ì‚¬ ê¸‰ì—¬,\n",
      "   2. [ì„¸ìœ¨ê³„ì‚°] ì†Œë“ì„¸ ë‚©ì„¸ ë²”ìœ„: ë†ì—…ì†Œë“, ì£¼íƒì„ëŒ€ì†Œë“ì œí•œ ì¡°ê±´, ì „í†µì£¼ ì œì¡°ì†Œë“, ì¼ë¶€ ì„ì—…ì†Œë“, ì–´ì—…ì†Œë“, íŠ¹ìˆ˜ ë³µë¬´\n",
      "   3. [ê·¼ë¡œì†Œë“] ê³µì ì—°ê¸ˆ ë° ê¸°íƒ€ì†Œë“ ê³¼ì„¸ ë²”ìœ„ ê³µì ì—°ê¸ˆ ë° ê´€ë ¨ ë³´ìƒê¸ˆ êµ­ê°€ë³´í›ˆ ë° íŠ¹ë³„ì§€ì›ê¸ˆ\n"
     ]
    }
   ],
   "source": [
    "# ê´€ë ¨ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°\n",
    "retriever = vector_database.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.get_relevant_documents(\"ì—°ë´‰ 5000ë§Œì›ì¸ ì§ì¥ì¸ì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì˜ˆìš”\")\n",
    "print(\"ğŸ” ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ:\")\n",
    "for i, doc in enumerate(docs):\n",
    "    title = doc.metadata.get('title', 'ì œëª©ì—†ìŒ')\n",
    "    category = doc.metadata.get('category', 'ê¸°íƒ€')\n",
    "    print(f\"   {i+1}. [{category}] {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b39d08da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¼ë¡œì†Œë“ì´ ìˆëŠ” ê±°ì£¼ìê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ê³µì œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ê³µìµì‹ íƒë²•ì— ë”°ë¥¸ ê³µìµì‹ íƒì˜ ì´ìµ**: ê³µìµì‹ íƒì—ì„œ ë°œìƒí•˜ëŠ” ì´ìµì€ ê·¼ë¡œì†Œë“ì—ì„œ ê³µì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì‚¬ì—…ì†Œë“**: íŠ¹ì • ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” ì‚¬ì—…ì†Œë“ë„ ê³µì œ ëŒ€ìƒì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë†ì—… ì†Œë“, ì£¼íƒ ì„ëŒ€ ì†Œë“(íŠ¹ì • ê¸°ì¤€ ì´í•˜), ì „í†µì£¼ ì œì¡° ì†Œë“ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê·¼ë¡œì†Œë“ê³¼ í‡´ì§ì†Œë“**: ë‹¤ìŒê³¼ ê°™ì€ ì†Œë“ì´ ê³µì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "   - ë³µë¬´ ì¤‘ì¸ ë³‘ì´ ë°›ëŠ” ê¸‰ì—¬\n",
      "   - ë²•ë¥ ì— ë”°ë¼ ë™ì›ëœ ì‚¬ëŒì´ ë°›ëŠ” ê¸‰ì—¬\n",
      "   - ì‚°ì—…ì¬í•´ë³´ìƒë³´í—˜ë²•ì— ë”°ë¥¸ ê°ì¢… ê¸‰ì—¬\n",
      "   - ê³ ìš©ë³´í—˜ë²•ì— ë”°ë¥¸ ì‹¤ì—…ê¸‰ì—¬, ìœ¡ì•„íœ´ì§ ê¸‰ì—¬ ë“±\n",
      "   - êµ­ë¯¼ì—°ê¸ˆë²•ì— ë”°ë¥¸ ë°˜í™˜ì¼ì‹œê¸ˆ ë° ì‚¬ë§ì¼ì‹œê¸ˆ\n",
      "   - ì™¸êµ­ì •ë¶€ ë˜ëŠ” êµ­ì œê¸°ê´€ì—ì„œ ê·¼ë¬´í•˜ëŠ” ê²½ìš°ì˜ ê¸‰ì—¬\n",
      "   - ë³µë¦¬í›„ìƒì  ì„±ì§ˆì˜ ê¸‰ì—¬ ë“±\n",
      "\n",
      "4. **ì—°ê¸ˆì†Œë“**: íŠ¹ì • ì—°ê¸ˆì†Œë“ë„ ê³µì œ ëŒ€ìƒì´ ë  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ê³µì ì—°ê¸ˆ ê´€ë ¨ë²•ì— ë”°ë¼ ë°›ëŠ” ìœ ì¡±ì—°ê¸ˆ, ì¥ì• ì—°ê¸ˆ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ ì¡°ê±´ì— ë”°ë¼ ì¶”ê°€ì ì¸ ê³µì œê°€ ê°€ëŠ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ê³µì œì˜ ì„¸ë¶€ ì‚¬í•­ì€ ê´€ë ¨ ë²•ë ¹ ë° ëŒ€í†µë ¹ë ¹ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, êµ¬ì²´ì ì¸ ìƒí™©ì— ë”°ë¼ ì „ë¬¸ê°€ì˜ ìƒë‹´ì„ ë°›ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "results = full_chain.invoke({\"question\":\"íšŒì‚¬ì›ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ê³µì œëŠ”?\"})\n",
    "print(results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d220d2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ê³µì œê°ë©´'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize_content(\"íšŒì‚¬ì›ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ê³µì œëŠ”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87553a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
